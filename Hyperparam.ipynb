{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f8a611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vggish/embedding:0\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "from importlib import import_module\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "vggish_input=import_module(\".torchvggish.vggish_input\",\"torchvggish-master_changed\")\n",
    "use_pretrained = True\n",
    "\n",
    "#GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "#損失関数\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#勾配計算手法?\n",
    "\n",
    "#optimizer = optim.SGD(params_to_update, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390d55d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 指定されたパスが見つかりません。: 'GetAudiosetSample/result/Music'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4b1652d7f1c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_file_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvalid_file_list\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# 画像データへのファイルパスとラベルを格納したリストを取得する\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mpath_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_path_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m## リストが変かもなのでみてみる\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-4b1652d7f1c1>\u001b[0m in \u001b[0;36mmake_path_list\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdir_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mfile_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#8割を学習用、残りを検証用にする\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 指定されたパスが見つかりません。: 'GetAudiosetSample/result/Music'"
     ]
    }
   ],
   "source": [
    "#データセットの定義？\n",
    "classes=[\"Speech\",\"Music\"]\n",
    "dataset_dir=\"GetAudiosetSample/result\"\n",
    "\n",
    "\n",
    "def make_path_list():\n",
    "    train_file_list=[]\n",
    "    valid_file_list=[]\n",
    "    for i in range(len(classes)):\n",
    "        dir_name=os.path.join(dataset_dir,classes[i]).replace(\"\\\\\",\"/\")\n",
    "        file_list=os.listdir(dir_name)\n",
    "        \n",
    "        #8割を学習用、残りを検証用にする\n",
    "        num_data = len(file_list)\n",
    "        num_split = int(num_data*0.8)\n",
    "        \n",
    "        train_file_list += [[os.path.join(dir_name, file).replace('\\\\', '/'), i] for file in file_list[:num_split] ]\n",
    "        valid_file_list += [[os.path.join(dir_name, file).replace('\\\\', '/'), i] for file in file_list[num_split:]]\n",
    "    return {\"train\":train_file_list,\"valid\":valid_file_list}\n",
    "# 画像データへのファイルパスとラベルを格納したリストを取得する\n",
    "path_dict = make_path_list()\n",
    "## リストが変かもなのでみてみる\n",
    "\n",
    "\n",
    "print('学習データファイル数 : ', len(path_dict[\"train\"]))\n",
    "##### 先頭3件だけ表示\n",
    "print(path_dict[\"train\"][:3])\n",
    "\n",
    "print('検証データファイル数 : ', len(path_dict[\"valid\"]))\n",
    "##### 先頭3件だけ表示\n",
    "print(path_dict[\"valid\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94164bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    '''\n",
    "    data_dictは[パス,番号]\n",
    "    '''\n",
    "    def __init__(self, path_dict,  phase='train'):\n",
    "        #self.data_dict = data_dict\n",
    "        self.data_dict = []\n",
    "        for path, label in path_dict:\n",
    "            for data in vggish_input.wavfile_to_examples(path):\n",
    "                self.data_dict.append([data, label])\n",
    "                \n",
    "        \n",
    "        self.phase = phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        wav_data,label = self.data_dict[index]\n",
    "        \n",
    "        return wav_data, label\n",
    "\n",
    "#DataSetを実際に作ってみる \n",
    "\n",
    "train_dataset = MyDataset(\n",
    "    path_dict=path_dict[\"train\"],\n",
    "    phase=\"train\"\n",
    ")\n",
    "\n",
    "valid_dataset = MyDataset(\n",
    "    path_dict=path_dict[\"valid\"],\n",
    "    phase=\"valid\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48030fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"学習用データ数 : \", len(train_dataset))\n",
    "print(\"検証用データ数 : \", len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloaderを用いてミニバッチを作成\n",
    "def gen_dataloader_dict(batch_size=10):\n",
    "    batch_size=10\n",
    "\n",
    "    train_dataloader=data.DataLoader(\n",
    "        train_dataset, batch_size = batch_size, shuffle=True\n",
    "    )\n",
    "    valid_dataloader=data.DataLoader(\n",
    "        valid_dataset, batch_size = batch_size//2, shuffle=True\n",
    "    )\n",
    "\n",
    "    dataloader_dict={\n",
    "        'train': train_dataloader, \n",
    "        'valid': valid_dataloader\n",
    "    }\n",
    "    return dataloader_dict\n",
    "\n",
    "\n",
    "#print(dataloader_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55022e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainer:\n",
    "    def __init__(self, _classfilter=nn.Sequential(\n",
    "                nn.Linear(128,64),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(64,5),\n",
    "                nn.Softmax(dim=1)\n",
    "                ), \n",
    "                _criterion=nn.CrossEntropyLoss(),\n",
    "                _optimizer = optim.SGD,#params_to_update, lr=0.01),\n",
    "                _lr=0.01,\n",
    "                 _weight_decay=0.0,\n",
    "                _update_param_names=\n",
    "                     ['classfilter.0.weight', 'classfilter.0.bias', \n",
    "                          'classfilter.2.weight','classfilter.2.bias'],\n",
    "                _print=False\n",
    "                ):\n",
    "        '''\n",
    "        _classfilter:クラスフィルタ層の中身をnn.Sequentialで宣言したものを入れる\n",
    "            nn.Sequential(\n",
    "                nn.Linear(128,64),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(64,5),\n",
    "                nn.Softmax()\n",
    "                )\n",
    "        \n",
    "        _num_epochs:学習時のエポック数\n",
    "        \n",
    "        _criterion:損失関数\n",
    "        _optimizer:最適化手法\n",
    "        _lr:学習の速度\n",
    "        '''\n",
    "        dbprint=(lambda x:print(x)) if _print else (lambda x:None)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.model = torch.hub.load('torchvggish-master_changed', 'vggish', source='local', preprocess=False,postprocess=False)\n",
    "        self.model.classfilter=_classfilter\n",
    "\n",
    "        \n",
    "        self.model=self.model.to(device)\n",
    "        self.model.eval()\n",
    "        #学習させるパラメータを格納\n",
    "        self.params_to_update=[]\n",
    "        #対象以外は勾配計算をせず、変化しないようにもする\n",
    "        for name,param in self.model.named_parameters():\n",
    "            if name in _update_param_names:\n",
    "                param.requires_grad = True\n",
    "                self.params_to_update.append(param)\n",
    "                #print(\"name : \",name)\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.lr=_lr\n",
    "        self.weight_decay=_weight_decay\n",
    "        self.criterion=_criterion\n",
    "        self.optimizer=_optimizer(self.params_to_update, self.lr,self.weight_decay)\n",
    "        dbprint(self.model)\n",
    "                \n",
    "    def train(self,dataloader_dict,_num_epochs=100,_print=False):\n",
    "        dbprint=(lambda x:print(x)) if _print else (lambda x:None)\n",
    "        #エポック数\n",
    "        self.num_epochs=_num_epochs\n",
    "        self.x=[]\n",
    "        self.y=[]\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            dbprint('Epoch {}/{}'.format(epoch+1,self.num_epochs))\n",
    "\n",
    "            for phase in ['train','valid']:\n",
    "                if phase == 'train':\n",
    "                    self.model.train()#学習モード\n",
    "                else:\n",
    "                    self.model.eval()#検証モード\n",
    "                #epoch全体の損失の輪と正解数\n",
    "                epoch_loss=0.0\n",
    "                epoch_corrects=0\n",
    "                count=0.0\n",
    "                #dbprint(phase)\n",
    "                for inputs, labels in dataloader_dict[phase]:\n",
    "                    #入力の確認\n",
    "                    #dbprint(len(inputs),len(labels))\n",
    "                    #勾配計算を初期化する\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                    with torch.set_grad_enabled(phase=='train'):\n",
    "                        #labelsをcudaに\n",
    "                        #dbprint(inputs.shape)\n",
    "                        labels=labels.to(device)\n",
    "                        inputs=inputs.to(device)\n",
    "                        outputs=self.model(inputs)\n",
    "\n",
    "                        #損失関数を計算\n",
    "                        loss=self.criterion(outputs, labels)\n",
    "                        #ラベルを予測\n",
    "                        _,preds = torch.max(outputs,1)\n",
    "\n",
    "                        #訓練時は逆伝搬の計算\n",
    "                        if phase == \"train\":\n",
    "                            #逆伝搬\n",
    "                            loss.backward()\n",
    "\n",
    "                            #パラメータ更新\n",
    "                            self.optimizer.step()\n",
    "\n",
    "                        #イテレーション結果の計算\n",
    "                        #lossの合計を更新\n",
    "                        #pytorchの使用上バッチ内の平均lossが計算されているのでデータ数をかけて合計にする\n",
    "                        #損失和を「全データの損失/データ数」で求めるせいらしい?\n",
    "                        #dbprint(len(inputs))\n",
    "                        epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                        #正解数の合計を更新\n",
    "                        epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                #epochのlossと正解数の表示\n",
    "                epoch_loss=epoch_loss/len(dataloader_dict[phase].dataset)\n",
    "                epoch_acc=epoch_corrects.double()/len(dataloader_dict[phase].dataset)\n",
    "\n",
    "                dbprint('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "                self.x.append(epoch_acc)\n",
    "                self.y.append(epoch)\n",
    "    \n",
    "    def graph(self,_title):\n",
    "        plt.plot(self.y[::2],[i.tolist() for i in self.x][::2], label=\"train\", color =\"Green\")\n",
    "        plt.plot(self.y[::2],[i.tolist() for i in self.x][1::2], label=\"valid\", color =\"Blue\")\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.title(_title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47544dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filters=[nn.Sequential(\n",
    "        nn.Linear(128,64),\n",
    "        nn.Sigmoid(),\n",
    "#        nn.Linear(64,32),\n",
    "#        nn.Sigmoid(),\n",
    "        nn.Linear(64,5),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "         #,\n",
    "#    nn.Sequential(\n",
    "#        nn.Linear(128,64),\n",
    "#        nn.Sigmoid(),\n",
    "#        nn.Linear(64,32),\n",
    "#       nn.Sigmoid(),\n",
    "#        nn.Linear(32,5),\n",
    "#        nn.Softmax(dim=1)\n",
    "#    )\n",
    "  ]\n",
    "\n",
    "lr_list=[0.0001,0.001,0.01,0.1,1,10,100]\n",
    "weight_decay_list=[0.00000001,0.0000001,\n",
    "                  0.000001,0.00001,0.0001,0.001,0.01,0.1,0,1,10]\n",
    "\n",
    "for fil in filters:\n",
    "    for LR in lr_list:\n",
    "        for WD in weight_decay_list:\n",
    "            train=trainer(_classfilter=copy.deepcopy(fil),_print=False,_lr=LR,_weight_decay=WD)#.to(device)\n",
    "            train.train(dataloader_dict=gen_dataloader_dict(),_print=False,_num_epochs=100)\n",
    "            train.graph(\"fil:{},lr={},weight_decay={}\".format(fil,LR,WD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f54f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_print=True\n",
    "dbprint=(lambda x:print(x)) if _print else (lambda x: None)\n",
    "dbprint(\"11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8435f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fdca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in dataloader_dict['train']:\n",
    "    print(a.shape,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c498309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac6e4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467017f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
