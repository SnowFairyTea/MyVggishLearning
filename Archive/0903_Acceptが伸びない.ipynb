{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f8a611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "#GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "#損失関数\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4968bc0",
   "metadata": {},
   "source": [
    "# 今日は試しに学習させてみる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1398ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vggish/embedding:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Download an example audio file\\nimport urllib\\nurl, filename = (\"http://soundbible.com/grab.php?id=1698&type=wav\", \"bus_chatter.wav\")\\ntry: urllib.URLopener().retrieve(url, filename)\\nexcept: urllib.request.urlretrieve(url, filename)\\n\\nmodel.forward(filename)```'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('torchvggish-master', 'vggish', source='local').to(device)\n",
    "#harritaylor/\n",
    "#model.eval()\n",
    "'''\n",
    "# Download an example audio file\n",
    "import urllib\n",
    "url, filename = (\"http://soundbible.com/grab.php?id=1698&type=wav\", \"bus_chatter.wav\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "model.forward(filename)```'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7201a52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyClassfilter(\n",
       "  (classfilter): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=64, out_features=5, bias=True)\n",
       "    (3): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyClassfilter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyClassfilter, self).__init__()\n",
    "        self.classfilter=nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64,5),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classfilter(x)\n",
    "mymodel = MyClassfilter().to(device)\n",
    "mymodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2adcdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGish(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (embeddings): Sequential(\n",
      "    (0): Linear(in_features=12288, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (pproc): Postprocessor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 学習済みの重みを使用\n",
    "use_pretrained = True\n",
    "\n",
    "# モデルをロード\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b2b9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('変更前 : ', model.embeddings[4])\n",
    "#model.embeddings[4] = nn.Linear(in_features=4096, out_features=5)\n",
    "#print('変更あと : ', model.embeddings[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8efc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.classfilter=nn.Sequential(\n",
    "#    nn.Linear(128, 5)   \n",
    "#)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f4dc622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 128]) 2\n",
      "tensor([[0.2262, 0.2551, 0.1663, 0.1464, 0.2060],\n",
      "        [0.1676, 0.2295, 0.1434, 0.1370, 0.3225],\n",
      "        [0.2315, 0.1791, 0.1734, 0.1499, 0.2661],\n",
      "        [0.1989, 0.1614, 0.1795, 0.1604, 0.2998],\n",
      "        [0.1654, 0.2012, 0.1570, 0.1632, 0.3133],\n",
      "        [0.2090, 0.1982, 0.1365, 0.1769, 0.2794],\n",
      "        [0.2230, 0.1580, 0.1485, 0.1756, 0.2949],\n",
      "        [0.1855, 0.2312, 0.1381, 0.1191, 0.3261],\n",
      "        [0.2627, 0.1755, 0.1241, 0.1627, 0.2750],\n",
      "        [0.2448, 0.1973, 0.1328, 0.1648, 0.2603],\n",
      "        [0.1725, 0.2101, 0.1352, 0.1641, 0.3182],\n",
      "        [0.1904, 0.1954, 0.1502, 0.1548, 0.3093],\n",
      "        [0.2410, 0.1821, 0.1573, 0.1519, 0.2677],\n",
      "        [0.2941, 0.1542, 0.1008, 0.1705, 0.2805],\n",
      "        [0.2129, 0.1270, 0.1406, 0.1781, 0.3415],\n",
      "        [0.2557, 0.2165, 0.1127, 0.1334, 0.2818],\n",
      "        [0.1793, 0.2325, 0.1382, 0.1599, 0.2901],\n",
      "        [0.2900, 0.1753, 0.1352, 0.1535, 0.2459],\n",
      "        [0.2046, 0.2197, 0.1905, 0.1362, 0.2490]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hase\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "#試しに実行\n",
    "#model.eval()# 評価しない\n",
    "import urllib\n",
    "url, filename = (\"http://soundbible.com/grab.php?id=1698&type=wav\", \"bus_chatter.wav\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "a =model.forward(filename)\n",
    "print(a.size(),a.dim())\n",
    "print(mymodel.forward(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "390d55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データ数 :  162\n",
      "[['C:/Users/hase/git/youtubedl/result/Speech/--aE2O5G5WE.wav', 0], ['C:/Users/hase/git/youtubedl/result/Speech/--PJHxphWEs.wav', 0], ['C:/Users/hase/git/youtubedl/result/Speech/-30H9V1IKps.wav', 0]]\n",
      "検証データ数 :  44\n",
      "[['C:/Users/hase/git/youtubedl/result/Speech/-L44JqysUy8.wav', 0], ['C:/Users/hase/git/youtubedl/result/Speech/-L68XDzhn2g.wav', 0], ['C:/Users/hase/git/youtubedl/result/Speech/-LBl0UeKNyU.wav', 0]]\n"
     ]
    }
   ],
   "source": [
    "#データセットの定義？\n",
    "classes=[\"Speech\",\"Wind\",\"Animal\",\"Music\",\"Speech\"]\n",
    "dataset_dir=\"C:/Users/hase/git/youtubedl/result\"\n",
    "\n",
    "\n",
    "def make_path_list():\n",
    "    train_file_list=[]\n",
    "    valid_file_list=[]\n",
    "    for i in range(len(classes)):\n",
    "        dir_name=os.path.join(dataset_dir,classes[i]).replace(\"\\\\\",\"/\")\n",
    "        file_list=os.listdir(dir_name)\n",
    "        \n",
    "        #8割を学習用、残りを検証用にする\n",
    "        num_data = len(file_list)\n",
    "        num_split = int(num_data*0.8)\n",
    "        \n",
    "        train_file_list += [[os.path.join(dir_name, file).replace('\\\\', '/'), i] for file in file_list[:num_split] ]\n",
    "        valid_file_list += [[os.path.join(dir_name, file).replace('\\\\', '/'), i] for file in file_list[num_split:]]\n",
    "    return {\"train\":train_file_list,\"valid\":valid_file_list}\n",
    "# 画像データへのファイルパスとラベルを格納したリストを取得する\n",
    "data_dict = make_path_list()\n",
    "## リストが変かもなのでみてみる\n",
    "\n",
    "\n",
    "print('学習データ数 : ', len(data_dict[\"train\"]))\n",
    "##### 先頭3件だけ表示\n",
    "print(data_dict[\"train\"][:3])\n",
    "\n",
    "print('検証データ数 : ', len(data_dict[\"valid\"]))\n",
    "##### 先頭3件だけ表示\n",
    "print(data_dict[\"valid\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94164bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C:/Users/hase/git/youtubedl/result/Speech/--aE2O5G5WE.wav', 0)\n"
     ]
    }
   ],
   "source": [
    "#0830\n",
    "#DataSet型を作る必要がある気がする\n",
    "class MyDataset(data.Dataset):\n",
    "    '''\n",
    "    data_dictは[パス,番号]\n",
    "    '''\n",
    "    def __init__(self, data_dict,  phase='train'):\n",
    "        self.data_dict = data_dict\n",
    "        self.phase = phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        wav_path,label = self.data_dict[index]\n",
    "        \n",
    "        return wav_path, label\n",
    "\n",
    "#DataSetを実際に作ってみる \n",
    "\n",
    "train_dataset = MyDataset(\n",
    "    data_dict=data_dict[\"train\"],\n",
    "    phase=\"train\"\n",
    ")\n",
    "\n",
    "valid_dataset = MyDataset(\n",
    "    data_dict=data_dict[\"valid\"],\n",
    "    phase=\"valid\"\n",
    ")\n",
    "\n",
    "#test\n",
    "print(train_dataset.__getitem__(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f0dd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x00000188C52FF7F0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x00000188AA097F70>}\n"
     ]
    }
   ],
   "source": [
    "#0830\n",
    "#もう1手ひつようらしい\n",
    "\n",
    "#dataloaderを用いてミニバッチを作成\n",
    "batch_size=10\n",
    "\n",
    "train_dataloader=data.DataLoader(\n",
    "    train_dataset, batch_size = batch_size, shuffle=True\n",
    ")\n",
    "valid_dataloader=data.DataLoader(\n",
    "    valid_dataset, batch_size = batch_size//2, shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_dict={\n",
    "    'train': train_dataloader, \n",
    "    'valid': valid_dataloader\n",
    "}\n",
    "print(dataloader_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b54849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  features.0.weight\n",
      "name :  features.0.bias\n",
      "name :  features.3.weight\n",
      "name :  features.3.bias\n",
      "name :  features.6.weight\n",
      "name :  features.6.bias\n",
      "name :  features.8.weight\n",
      "name :  features.8.bias\n",
      "name :  features.11.weight\n",
      "name :  features.11.bias\n",
      "name :  features.13.weight\n",
      "name :  features.13.bias\n",
      "name :  embeddings.0.weight\n",
      "name :  embeddings.0.bias\n",
      "name :  embeddings.2.weight\n",
      "name :  embeddings.2.bias\n",
      "name :  embeddings.4.weight\n",
      "name :  embeddings.4.bias\n",
      "name :  pproc.pca_eigen_vectors\n",
      "name :  pproc.pca_means\n",
      "('classfilter.0.weight', Parameter containing:\n",
      "tensor([[ 0.0309, -0.0719,  0.0402,  ...,  0.0508,  0.0277,  0.0434],\n",
      "        [ 0.0549,  0.0020, -0.0454,  ..., -0.0277,  0.0309,  0.0831],\n",
      "        [ 0.0085, -0.0480,  0.0121,  ...,  0.0293, -0.0255,  0.0251],\n",
      "        ...,\n",
      "        [ 0.0552, -0.0281, -0.0412,  ..., -0.0605, -0.0760, -0.0413],\n",
      "        [-0.0836,  0.0755,  0.0882,  ..., -0.0137, -0.0279, -0.0351],\n",
      "        [-0.0752,  0.0338,  0.0015,  ..., -0.0301,  0.0258,  0.0577]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('classfilter.0.bias', Parameter containing:\n",
      "tensor([ 0.0037,  0.0677,  0.0032,  0.0315,  0.0405, -0.0820,  0.0502,  0.0476,\n",
      "         0.0618,  0.0019,  0.0550,  0.0656, -0.0253,  0.0165,  0.0462,  0.0668,\n",
      "        -0.0532,  0.0095, -0.0813,  0.0767, -0.0582,  0.0875,  0.0496,  0.0311,\n",
      "        -0.0639,  0.0202, -0.0645, -0.0752,  0.0582,  0.0465,  0.0146, -0.0483,\n",
      "         0.0465,  0.0773, -0.0650,  0.0206,  0.0352, -0.0069,  0.0420, -0.0340,\n",
      "        -0.0668,  0.0141,  0.0020,  0.0521, -0.0299, -0.0553, -0.0724,  0.0026,\n",
      "         0.0276, -0.0757, -0.0595,  0.0730,  0.0600, -0.0440, -0.0288,  0.0251,\n",
      "         0.0502,  0.0162, -0.0566,  0.0134, -0.0133,  0.0410, -0.0054,  0.0550],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('classfilter.2.weight', Parameter containing:\n",
      "tensor([[ 0.0910,  0.0683, -0.0393, -0.0655, -0.0016,  0.0322, -0.0716,  0.0812,\n",
      "          0.0554, -0.0698, -0.0409, -0.0882, -0.1038,  0.0371, -0.0045,  0.0083,\n",
      "          0.0276,  0.0026,  0.0584, -0.1113,  0.0045, -0.0136, -0.0032,  0.0745,\n",
      "          0.1039, -0.1087, -0.0621, -0.0418,  0.0865,  0.0948,  0.0921,  0.0941,\n",
      "          0.1025, -0.0719,  0.0614,  0.0229,  0.0674,  0.0668,  0.0383,  0.1225,\n",
      "         -0.0118,  0.0531,  0.0494,  0.0596,  0.0616, -0.1143,  0.0143,  0.0204,\n",
      "         -0.0510, -0.0108, -0.0965, -0.0301,  0.0332,  0.0431,  0.0415,  0.0997,\n",
      "         -0.0504,  0.0736,  0.0391, -0.0512,  0.1199, -0.0108, -0.0872,  0.0554],\n",
      "        [ 0.0975, -0.1042, -0.0531,  0.0865,  0.1009, -0.0777, -0.1210, -0.1173,\n",
      "          0.0423, -0.0266, -0.0535,  0.0518,  0.0599, -0.0095,  0.0087, -0.0552,\n",
      "         -0.0325, -0.0407,  0.0978,  0.0559, -0.0535, -0.1114,  0.0488, -0.0111,\n",
      "          0.0029, -0.0143,  0.0879,  0.0918, -0.0843,  0.0312,  0.0929, -0.0441,\n",
      "         -0.0569, -0.0952,  0.0441,  0.0880,  0.0490,  0.0299, -0.0419,  0.1063,\n",
      "         -0.0274,  0.1192, -0.0810,  0.0095,  0.0045,  0.0241, -0.0113,  0.0098,\n",
      "          0.0209,  0.0645,  0.0932,  0.0669,  0.0331, -0.0931, -0.0644, -0.1244,\n",
      "         -0.0412, -0.0999, -0.0897, -0.0553, -0.0258,  0.0011,  0.0802,  0.1247],\n",
      "        [-0.0832, -0.0392,  0.0115,  0.0800,  0.0045,  0.1245,  0.0428,  0.0120,\n",
      "          0.0293, -0.0080,  0.0141,  0.1217,  0.0632,  0.0796,  0.0920,  0.0471,\n",
      "         -0.0579, -0.0867,  0.0215,  0.1054,  0.0869, -0.0158, -0.1179,  0.0517,\n",
      "          0.0588,  0.0924, -0.0240, -0.1029,  0.0952, -0.0028, -0.0884, -0.0812,\n",
      "         -0.0905,  0.0819,  0.1021,  0.0657,  0.0293,  0.0627, -0.0365, -0.1043,\n",
      "          0.0741, -0.0523, -0.0652, -0.0971, -0.0355, -0.0623,  0.1226, -0.0245,\n",
      "          0.1035, -0.1068, -0.0841, -0.1103, -0.1183, -0.1007, -0.0576,  0.0864,\n",
      "         -0.0144,  0.0637, -0.0172,  0.0091, -0.0205, -0.0239,  0.0477, -0.1199],\n",
      "        [-0.0358,  0.0916,  0.0056,  0.0248, -0.0807,  0.0626, -0.0937,  0.1210,\n",
      "          0.1246, -0.0807, -0.1077, -0.0071, -0.0221, -0.0212, -0.0204, -0.1248,\n",
      "          0.1095,  0.0345,  0.1116, -0.0668, -0.0170,  0.0823, -0.0102,  0.0233,\n",
      "          0.0986,  0.0374,  0.0437, -0.1229,  0.0928, -0.1171,  0.0146,  0.0636,\n",
      "          0.1101,  0.1029, -0.0992, -0.0038,  0.0684, -0.0589,  0.0905,  0.1217,\n",
      "         -0.0534, -0.0729, -0.0563, -0.0594, -0.0514, -0.1246, -0.0511, -0.0328,\n",
      "         -0.1148,  0.0527, -0.0378, -0.0054,  0.0171, -0.0791,  0.1050, -0.0044,\n",
      "         -0.1059,  0.0861, -0.0166,  0.0295, -0.0263, -0.0488, -0.0126, -0.0323],\n",
      "        [ 0.0082, -0.0423,  0.1114, -0.0089, -0.0523,  0.0816, -0.0939, -0.0963,\n",
      "         -0.0540,  0.1016, -0.0581,  0.0779,  0.0903,  0.1011,  0.0970, -0.0261,\n",
      "         -0.0852,  0.1154, -0.0910,  0.1047, -0.0439, -0.0165,  0.0636,  0.0021,\n",
      "         -0.0127,  0.0647, -0.0310,  0.1228, -0.0462,  0.0108,  0.1074, -0.0115,\n",
      "         -0.0296, -0.0195, -0.0393, -0.0441,  0.0049, -0.0670, -0.0261,  0.0439,\n",
      "         -0.0767,  0.0384,  0.1194, -0.0765, -0.0027,  0.0356, -0.0814,  0.0967,\n",
      "         -0.1066,  0.0891,  0.0298,  0.0832, -0.0922,  0.1202,  0.1134,  0.1049,\n",
      "         -0.1044, -0.1116,  0.0390,  0.0118,  0.0358,  0.0455, -0.0400, -0.0559]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('classfilter.2.bias', Parameter containing:\n",
      "tensor([ 0.0848,  0.0324,  0.0577,  0.0737, -0.0134], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "<generator object Module.parameters at 0x000001889D9CFBA0>\n"
     ]
    }
   ],
   "source": [
    "# パラメータ名の確認\n",
    "for name, param in model.named_parameters():\n",
    "    print('name : ', name)\n",
    "for prm in mymodel.named_parameters():\n",
    "    print(prm)\n",
    "print(mymodel.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b35bef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  classfilter.0.weight\n",
      "name :  classfilter.0.bias\n",
      "name :  classfilter.2.weight\n",
      "name :  classfilter.2.bias\n"
     ]
    }
   ],
   "source": [
    "#学習させるパラメータを格納\n",
    "params_to_update=[]\n",
    "#学習させるパラメータ名\n",
    "update_param_names=['classfilter.0.weight', 'classfilter.0.bias', 'classfilter.2.weight',\n",
    "                   'classfilter.2.bias']\n",
    "\n",
    "#対象以外は購買計算をせず、変化しないようにもする\n",
    "for name,param in mymodel.named_parameters():\n",
    "    if name in update_param_names:\n",
    "        param.requires_grad = True\n",
    "        params_to_update.append(param)\n",
    "        print(\"name : \",name)\n",
    "    else:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80179db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#optimizer = optim.SGD(params_to_update, lr=0.01)\n",
    "optimizer = optim.SGD(params_to_update, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e9128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "train Loss: 15.3533 Acc: 0.1790\n",
      "valid Loss: 7.8496 Acc: 0.2045\n",
      "Epoch 2/20\n",
      "train Loss: 15.2909 Acc: 0.2099\n",
      "valid Loss: 7.8506 Acc: 0.2045\n",
      "Epoch 3/20\n",
      "train Loss: 15.2477 Acc: 0.2778\n",
      "valid Loss: 7.8316 Acc: 0.2045\n",
      "Epoch 4/20\n",
      "train Loss: 15.2164 Acc: 0.3210\n",
      "valid Loss: 7.8255 Acc: 0.2727\n",
      "Epoch 5/20\n",
      "train Loss: 15.2040 Acc: 0.2963\n",
      "valid Loss: 7.8288 Acc: 0.2500\n",
      "Epoch 6/20\n",
      "train Loss: 15.1888 Acc: 0.3210\n",
      "valid Loss: 7.8251 Acc: 0.2955\n",
      "Epoch 7/20\n",
      "train Loss: 15.1935 Acc: 0.2963\n",
      "valid Loss: 7.8214 Acc: 0.2727\n",
      "Epoch 8/20\n",
      "train Loss: 15.1427 Acc: 0.3889\n",
      "valid Loss: 7.8166 Acc: 0.3182\n",
      "Epoch 9/20\n",
      "train Loss: 15.1432 Acc: 0.3333\n",
      "valid Loss: 7.7996 Acc: 0.3182\n",
      "Epoch 10/20\n",
      "train Loss: 15.0996 Acc: 0.3272\n",
      "valid Loss: 7.8107 Acc: 0.1818\n",
      "Epoch 11/20\n",
      "train Loss: 15.1055 Acc: 0.2963\n",
      "valid Loss: 7.7933 Acc: 0.2273\n",
      "Epoch 12/20\n",
      "train Loss: 15.0791 Acc: 0.3148\n",
      "valid Loss: 7.8050 Acc: 0.2273\n",
      "Epoch 13/20\n",
      "train Loss: 15.0702 Acc: 0.2593\n",
      "valid Loss: 7.7933 Acc: 0.2045\n",
      "Epoch 14/20\n",
      "train Loss: 15.0147 Acc: 0.2531\n",
      "valid Loss: 7.8115 Acc: 0.2727\n",
      "Epoch 15/20\n",
      "train Loss: 15.0261 Acc: 0.2593\n",
      "valid Loss: 7.8040 Acc: 0.2500\n",
      "Epoch 16/20\n",
      "train Loss: 15.0301 Acc: 0.2654\n",
      "valid Loss: 7.8043 Acc: 0.2727\n",
      "Epoch 17/20\n",
      "train Loss: 14.9945 Acc: 0.2901\n",
      "valid Loss: 7.7857 Acc: 0.2500\n",
      "Epoch 18/20\n",
      "train Loss: 15.0169 Acc: 0.2963\n",
      "valid Loss: 7.7805 Acc: 0.2727\n",
      "Epoch 19/20\n",
      "train Loss: 14.9735 Acc: 0.3580\n",
      "valid Loss: 7.7822 Acc: 0.2727\n",
      "Epoch 20/20\n",
      "train Loss: 14.9697 Acc: 0.3827\n",
      "valid Loss: 7.7778 Acc: 0.2727\n"
     ]
    }
   ],
   "source": [
    "#エポック数\n",
    "num_epochs=20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1,num_epochs))\n",
    "    \n",
    "    for phase in ['train','valid']:\n",
    "        if phase == 'train':\n",
    "            model.train()#学習モード\n",
    "        else:\n",
    "            model.eval()#検証？\n",
    "    \n",
    "        #epoch全体の損失の輪と正解数\n",
    "        epoch_loss=0.0\n",
    "        epoch_corrects=0\n",
    "        #print(phase)\n",
    "        for inputs, labels in dataloader_dict[phase]:\n",
    "            #入力の確認\n",
    "            #print(len(inputs),len(labels))\n",
    "            #optimizer?を初期化?する?\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    "                #ここでエラー、ファイルパスの型を調べてみる\n",
    "                #strかnp.ndarrayじゃないといけない\n",
    "                \n",
    "                #print(type(inputs))#<class 'tuple'>\n",
    "                \n",
    "                #0831入力がSTRになるようにしてみる\n",
    "                #\"outputs=model(inputs)\n",
    "                #RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 3.00 GiB total capacity; 1.76 GiB already allocated; 1.55 MiB free; 1.87 GiB reserved in total by PyTorch)\n",
    "\n",
    "                #outputs=[model(input) for input in inputs]\n",
    "                #print(outputs)\n",
    "                #tensor型にする\n",
    "                #0903 毎回やってみる\n",
    "             #   outputs=torch.tensor([model(input).tolist()[0] for input in inputs])\n",
    "                outputs=mymodel(torch.tensor([model(input).tolist()[0] for input in inputs]).to(device))\n",
    "               # print(\"outputs:\", outputs.dim())\n",
    "               # print(outputs.size())\n",
    "                #損失を計算\n",
    "                #ここでエラーAttributeError: 'int' object has no attribute 'size'\n",
    "                #ちゃんとしたDataset肩を作って直した\n",
    "               # print(outputs)#二次元tensor配列\n",
    "               # print(labels)#0\n",
    "                labels=labels.to(device)\n",
    "                loss=criterion(outputs, labels)\n",
    "                #print(outputs, labels)\n",
    "                #ラベルを予測\n",
    "                _,preds = torch.max(outputs,1)\n",
    "                \n",
    "                #訓練時は逆伝搬の計算\n",
    "                if phase == \"train\":\n",
    "                    #逆伝搬\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    #パラメータ更新\n",
    "                    optimizer.step()\n",
    "                \n",
    "                #イテレーション結果の計算\n",
    "                #lossの合計を更新\n",
    "                #pytorchの使用上バッチ内の平均lossが計算されているのでデータ数をかけて合計にする\n",
    "                #損失和を「全データの損失/データ数」で求めるために必要らしい?\n",
    "                #print(len(inputs))\n",
    "                epoch_loss += loss.item()*len(inputs)\n",
    "                \n",
    "                #正解数の合計を更新\n",
    "                epoch_corrects += torch.sum(preds == labels.data)\n",
    "        #epochのlossと正解数の表示\n",
    "        epoch_loss=epoch_loss/len(dataloader_dict[phase])\n",
    "        epoch_acc=epoch_corrects.double()/len(dataloader_dict[phase].dataset)\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=2)\n",
    "input = torch.randn(4, 4)\n",
    "output = m(input)\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0db113",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "input = torch.randn(2)\n",
    "output = m(input)\n",
    "print(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1e93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562ad1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b45a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e7787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da7082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81b581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ee9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459ef847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013da01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2c9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bcca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed3a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
