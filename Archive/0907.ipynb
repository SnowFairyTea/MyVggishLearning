{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f8a611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "#GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "#損失関数\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4968bc0",
   "metadata": {},
   "source": [
    "# 今日は試しに学習させてみる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1398ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vggish/embedding:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Download an example audio file\\nimport urllib\\nurl, filename = (\"http://soundbible.com/grab.php?id=1698&type=wav\", \"bus_chatter.wav\")\\ntry: urllib.URLopener().retrieve(url, filename)\\nexcept: urllib.request.urlretrieve(url, filename)\\n\\nmodel.forward(filename)```'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('torchvggish-master', 'vggish', source='local').to(device)\n",
    "#harritaylor/\n",
    "#model.eval()\n",
    "'''\n",
    "# Download an example audio file\n",
    "import urllib\n",
    "url, filename = (\"http://soundbible.com/grab.php?id=1698&type=wav\", \"bus_chatter.wav\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "model.forward(filename)```'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7201a52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyClassfilter(\n",
       "  (classfilter): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=64, out_features=5, bias=True)\n",
       "    (3): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyClassfilter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyClassfilter, self).__init__()\n",
    "        self.classfilter=nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64,5),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classfilter(x)\n",
    "mymodel = MyClassfilter().to(device)\n",
    "mymodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2adcdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGish(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (embeddings): Sequential(\n",
      "    (0): Linear(in_features=12288, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (pproc): Postprocessor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 学習済みの重みを使用\n",
    "use_pretrained = True\n",
    "\n",
    "# モデルをロード\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b2b9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('変更前 : ', model.embeddings[4])\n",
    "#model.embeddings[4] = nn.Linear(in_features=4096, out_features=5)\n",
    "#print('変更あと : ', model.embeddings[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8efc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.classfilter=nn.Sequential(\n",
    "#    nn.Linear(128, 5)   \n",
    "#)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f4dc622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#試しに実行\n",
    "#model.eval()# 評価しない\n",
    "import urllib\n",
    "url, filename = (\"http://soundbible.com/grab.php?id=1698&type=wav\", \"bus_chatter.wav\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "#a =model.forward(filename)\n",
    "#rint(a.size(),a.dim())\n",
    "#print(mymodel.forward(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "390d55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データ数 :  162\n",
      "[['C:/Users/hase/git/youtubedl/result/Speech/--aE2O5G5WE.wav', 0], ['C:/Users/hase/git/youtubedl/result/Speech/--PJHxphWEs.wav', 0], ['C:/Users/hase/git/youtubedl/result/Speech/-30H9V1IKps.wav', 0]]\n",
      "検証データ数 :  44\n",
      "[['C:/Users/hase/git/youtubedl/result/Speech/-L44JqysUy8.wav', 0], ['C:/Users/hase/git/youtubedl/result/Speech/-L68XDzhn2g.wav', 0], ['C:/Users/hase/git/youtubedl/result/Speech/-LBl0UeKNyU.wav', 0]]\n"
     ]
    }
   ],
   "source": [
    "#データセットの定義？\n",
    "classes=[\"Speech\",\"Wind\",\"Animal\",\"Music\",\"Speech\"]\n",
    "dataset_dir=\"C:/Users/hase/git/youtubedl/result\"\n",
    "\n",
    "\n",
    "def make_path_list():\n",
    "    train_file_list=[]\n",
    "    valid_file_list=[]\n",
    "    for i in range(len(classes)):\n",
    "        dir_name=os.path.join(dataset_dir,classes[i]).replace(\"\\\\\",\"/\")\n",
    "        file_list=os.listdir(dir_name)\n",
    "        \n",
    "        #8割を学習用、残りを検証用にする\n",
    "        num_data = len(file_list)\n",
    "        num_split = int(num_data*0.8)\n",
    "        \n",
    "        train_file_list += [[os.path.join(dir_name, file).replace('\\\\', '/'), i] for file in file_list[:num_split] ]\n",
    "        valid_file_list += [[os.path.join(dir_name, file).replace('\\\\', '/'), i] for file in file_list[num_split:]]\n",
    "    return {\"train\":train_file_list,\"valid\":valid_file_list}\n",
    "# 画像データへのファイルパスとラベルを格納したリストを取得する\n",
    "data_dict = make_path_list()\n",
    "## リストが変かもなのでみてみる\n",
    "\n",
    "\n",
    "print('学習データ数 : ', len(data_dict[\"train\"]))\n",
    "##### 先頭3件だけ表示\n",
    "print(data_dict[\"train\"][:3])\n",
    "\n",
    "print('検証データ数 : ', len(data_dict[\"valid\"]))\n",
    "##### 先頭3件だけ表示\n",
    "print(data_dict[\"valid\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94164bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C:/Users/hase/git/youtubedl/result/Speech/--aE2O5G5WE.wav', 0)\n"
     ]
    }
   ],
   "source": [
    "#0830\n",
    "#DataSet型を作る必要がある気がする\n",
    "class MyDataset(data.Dataset):\n",
    "    '''\n",
    "    data_dictは[パス,番号]\n",
    "    '''\n",
    "    def __init__(self, data_dict,  phase='train'):\n",
    "        self.data_dict = data_dict\n",
    "        self.phase = phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        wav_path,label = self.data_dict[index]\n",
    "        \n",
    "        return wav_path, label\n",
    "\n",
    "#DataSetを実際に作ってみる \n",
    "\n",
    "train_dataset = MyDataset(\n",
    "    data_dict=data_dict[\"train\"],\n",
    "    phase=\"train\"\n",
    ")\n",
    "\n",
    "valid_dataset = MyDataset(\n",
    "    data_dict=data_dict[\"valid\"],\n",
    "    phase=\"valid\"\n",
    ")\n",
    "\n",
    "#test\n",
    "print(train_dataset.__getitem__(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f0dd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x000001D00467C460>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x000001D00467C5E0>}\n"
     ]
    }
   ],
   "source": [
    "#0830\n",
    "#もう1手ひつようらしい\n",
    "\n",
    "#dataloaderを用いてミニバッチを作成\n",
    "batch_size=10\n",
    "\n",
    "train_dataloader=data.DataLoader(\n",
    "    train_dataset, batch_size = batch_size, shuffle=True\n",
    ")\n",
    "valid_dataloader=data.DataLoader(\n",
    "    valid_dataset, batch_size = batch_size//2, shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_dict={\n",
    "    'train': train_dataloader, \n",
    "    'valid': valid_dataloader\n",
    "}\n",
    "print(dataloader_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b54849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  features.0.weight\n",
      "name :  features.0.bias\n",
      "name :  features.3.weight\n",
      "name :  features.3.bias\n",
      "name :  features.6.weight\n",
      "name :  features.6.bias\n",
      "name :  features.8.weight\n",
      "name :  features.8.bias\n",
      "name :  features.11.weight\n",
      "name :  features.11.bias\n",
      "name :  features.13.weight\n",
      "name :  features.13.bias\n",
      "name :  embeddings.0.weight\n",
      "name :  embeddings.0.bias\n",
      "name :  embeddings.2.weight\n",
      "name :  embeddings.2.bias\n",
      "name :  embeddings.4.weight\n",
      "name :  embeddings.4.bias\n",
      "name :  pproc.pca_eigen_vectors\n",
      "name :  pproc.pca_means\n",
      "('classfilter.0.weight', Parameter containing:\n",
      "tensor([[ 0.0415, -0.0314,  0.0773,  ...,  0.0744, -0.0014,  0.0186],\n",
      "        [ 0.0200,  0.0314,  0.0122,  ..., -0.0118,  0.0340,  0.0601],\n",
      "        [ 0.0310,  0.0439, -0.0441,  ..., -0.0067,  0.0132,  0.0759],\n",
      "        ...,\n",
      "        [ 0.0849,  0.0634, -0.0015,  ..., -0.0235, -0.0794, -0.0627],\n",
      "        [-0.0866, -0.0532, -0.0156,  ..., -0.0122, -0.0631, -0.0340],\n",
      "        [-0.0394,  0.0767, -0.0270,  ...,  0.0336,  0.0545, -0.0727]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('classfilter.0.bias', Parameter containing:\n",
      "tensor([ 0.0205,  0.0287, -0.0853,  0.0296, -0.0038, -0.0278,  0.0162, -0.0262,\n",
      "        -0.0354,  0.0537, -0.0116, -0.0042, -0.0706, -0.0728,  0.0796, -0.0536,\n",
      "        -0.0522,  0.0057, -0.0780, -0.0827,  0.0573,  0.0253,  0.0706, -0.0259,\n",
      "         0.0598,  0.0423,  0.0308,  0.0565,  0.0838,  0.0795, -0.0209,  0.0522,\n",
      "         0.0285, -0.0416,  0.0853,  0.0480, -0.0690,  0.0749,  0.0703, -0.0345,\n",
      "        -0.0665,  0.0286,  0.0145, -0.0763,  0.0062, -0.0633,  0.0180,  0.0470,\n",
      "        -0.0534, -0.0456,  0.0786,  0.0718,  0.0028,  0.0158, -0.0085, -0.0373,\n",
      "         0.0391, -0.0137,  0.0327,  0.0468, -0.0125,  0.0697, -0.0431, -0.0776],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('classfilter.2.weight', Parameter containing:\n",
      "tensor([[-3.1281e-02,  8.0219e-02, -1.2072e-01, -8.3242e-03, -6.6532e-02,\n",
      "         -8.6232e-02,  8.5445e-02, -8.8606e-02, -2.4652e-03,  6.6071e-02,\n",
      "         -9.3950e-02,  2.9374e-02,  5.7860e-02,  8.6041e-02, -4.0398e-03,\n",
      "          3.1362e-02, -1.3479e-02, -1.1568e-01, -7.1632e-03, -1.3235e-02,\n",
      "          2.7978e-02, -1.6254e-02, -1.2235e-01, -6.8038e-02,  8.2782e-02,\n",
      "          9.3271e-04,  1.6752e-02,  9.6498e-02,  2.7337e-02, -1.1614e-01,\n",
      "          5.9237e-03, -2.5687e-02,  1.1874e-01, -6.0155e-02, -7.6893e-02,\n",
      "         -6.5108e-02, -4.7306e-02,  4.7271e-02, -4.2520e-02,  1.0520e-01,\n",
      "         -6.4703e-02,  2.0778e-03,  5.9146e-02,  6.1116e-03, -2.3328e-03,\n",
      "          5.0241e-02,  1.0307e-01, -2.6002e-02, -1.0664e-01,  9.2745e-03,\n",
      "         -8.3210e-02,  1.1680e-01,  9.0436e-02, -1.0346e-01,  5.2996e-02,\n",
      "          6.9644e-02,  5.7946e-02,  8.2998e-02,  1.3601e-02, -9.8772e-02,\n",
      "          6.1381e-02, -2.0196e-02, -2.7507e-02, -1.2116e-01],\n",
      "        [ 8.4275e-03,  7.9186e-02,  6.1337e-02,  2.2504e-02, -9.2833e-02,\n",
      "          4.8744e-02,  2.3715e-03,  4.8417e-02, -7.1015e-02,  1.2790e-02,\n",
      "         -6.2277e-02, -1.1347e-01,  2.2211e-02,  7.8618e-02, -1.2450e-01,\n",
      "         -2.9779e-02,  1.1841e-01, -5.2317e-02, -1.2903e-02,  6.5410e-02,\n",
      "         -8.5515e-02,  7.3457e-02, -1.2958e-03, -8.8887e-02, -7.9396e-03,\n",
      "          2.1625e-02, -6.7150e-02, -5.8978e-03,  8.5664e-02,  2.9286e-02,\n",
      "          4.3898e-02, -3.7776e-03,  6.5991e-02,  2.0635e-03, -7.4985e-02,\n",
      "          4.2066e-02,  4.4243e-02,  8.1233e-02,  7.8116e-02, -2.4579e-02,\n",
      "          1.0770e-01,  4.0268e-02, -8.6876e-02, -5.8144e-02,  4.5393e-02,\n",
      "         -6.6399e-02, -9.8368e-02, -5.0067e-02,  5.2610e-02, -1.1653e-01,\n",
      "          1.0378e-01, -9.8843e-02, -7.1283e-02, -4.4798e-02,  5.8871e-02,\n",
      "         -7.5031e-02, -1.1851e-01, -1.0809e-01,  8.4798e-02,  7.3259e-02,\n",
      "          7.5158e-02,  1.1440e-01, -6.7370e-03, -7.0862e-03],\n",
      "        [ 1.0434e-01,  8.3021e-02, -1.1348e-01,  5.1550e-02,  2.2130e-02,\n",
      "         -2.6802e-02, -8.6253e-02,  1.0618e-01, -1.0526e-01,  1.1406e-01,\n",
      "          2.0962e-02, -3.4148e-02, -6.0555e-02,  6.1719e-02,  8.4249e-02,\n",
      "          4.4687e-03,  3.0189e-02,  3.0900e-02, -1.7848e-03,  5.7377e-02,\n",
      "          2.3645e-02, -1.3853e-02,  8.1452e-03, -1.8544e-02,  1.0729e-01,\n",
      "          4.1942e-02,  2.2292e-03,  6.7033e-02, -3.0448e-02, -7.2375e-03,\n",
      "         -3.8204e-03,  1.2444e-01, -7.0358e-02,  8.0743e-02,  1.1493e-01,\n",
      "         -7.2971e-02,  6.1486e-02,  4.5030e-02,  2.1484e-02,  2.3138e-02,\n",
      "          9.5789e-02, -7.7840e-02,  7.6910e-02,  1.3286e-02, -7.8885e-02,\n",
      "          9.2083e-02,  4.5902e-02,  1.1674e-01, -3.1879e-02,  8.1947e-02,\n",
      "         -1.1276e-01,  8.3909e-02,  1.0021e-01,  8.3335e-02,  7.5947e-02,\n",
      "          1.3113e-02, -8.7389e-02, -8.6505e-02,  1.1825e-02,  1.1431e-01,\n",
      "         -1.0948e-01, -5.9819e-02, -1.0963e-01, -9.6350e-02],\n",
      "        [-8.5589e-02,  1.0958e-01,  1.1111e-01,  3.3852e-02, -1.0712e-01,\n",
      "         -2.1554e-02, -5.3157e-02, -2.2352e-02, -7.8559e-02, -3.4113e-02,\n",
      "         -1.1847e-01,  6.9738e-02,  1.1444e-02,  6.1302e-02, -1.1067e-01,\n",
      "         -1.1692e-01,  8.8977e-02,  1.2620e-02,  2.2843e-05,  3.3469e-02,\n",
      "         -7.5192e-02,  3.6585e-02,  1.1808e-01, -6.4041e-02, -1.2495e-01,\n",
      "          1.2350e-01, -1.0259e-01, -1.1575e-01, -9.1228e-02, -1.1032e-01,\n",
      "          7.5312e-02, -2.3707e-02, -6.8103e-02, -8.6042e-02,  1.1102e-01,\n",
      "         -1.6828e-02, -6.1662e-02,  8.0556e-02,  1.2150e-01,  6.4219e-02,\n",
      "         -4.9752e-02,  3.7669e-02,  1.1386e-01, -2.8512e-03, -1.9967e-02,\n",
      "          1.5873e-02,  1.2375e-01, -5.4407e-02, -9.3689e-02,  9.4995e-02,\n",
      "         -5.7880e-02, -5.4361e-02,  1.1384e-01, -1.2462e-01, -4.9979e-02,\n",
      "          5.1595e-02, -5.9730e-02,  8.0269e-02, -1.0527e-01,  3.1360e-02,\n",
      "          8.0922e-02,  8.7700e-02,  2.0896e-02,  6.5593e-02],\n",
      "        [ 3.9611e-02, -1.7014e-02,  8.5357e-02, -4.8625e-02,  7.0379e-02,\n",
      "         -3.8606e-03, -4.0076e-02,  7.4942e-02,  6.6682e-02, -1.1287e-01,\n",
      "          2.8485e-02, -2.7964e-02, -3.9837e-02, -6.3770e-02,  1.2951e-02,\n",
      "          5.4313e-02,  1.7218e-02,  2.9898e-02,  2.1121e-02,  1.1760e-01,\n",
      "         -1.1036e-01, -1.7385e-03, -2.3533e-02,  9.2469e-02, -2.6615e-02,\n",
      "          1.0937e-01, -1.9376e-02,  9.9381e-03,  9.0859e-02, -9.5529e-02,\n",
      "          1.4602e-03,  1.0692e-01, -2.4821e-02,  7.1036e-02, -8.5351e-02,\n",
      "          7.2365e-02, -6.8636e-02,  1.0971e-01,  1.2106e-01, -1.0025e-01,\n",
      "          1.3011e-03, -2.7297e-02,  2.4385e-02, -1.1198e-01, -6.2496e-02,\n",
      "         -1.2123e-01,  8.6578e-03,  1.0339e-01, -5.8303e-02,  1.2596e-02,\n",
      "          2.3589e-02, -1.8527e-02,  3.5569e-02,  6.0932e-02, -1.1745e-01,\n",
      "         -3.9451e-02,  7.7360e-02,  6.1084e-02,  7.9341e-02, -1.0362e-02,\n",
      "          1.1413e-01,  1.2274e-01,  3.4464e-02, -9.6345e-02]], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('classfilter.2.bias', Parameter containing:\n",
      "tensor([-0.0150,  0.0295, -0.0314, -0.0829, -0.0620], device='cuda:0',\n",
      "       requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "# パラメータ名の確認\n",
    "for name, param in model.named_parameters():\n",
    "    print('name : ', name)\n",
    "for prm in mymodel.named_parameters():\n",
    "    print(prm)\n",
    "#print(mymodel.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b35bef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  classfilter.0.weight\n",
      "name :  classfilter.0.bias\n",
      "name :  classfilter.2.weight\n"
     ]
    }
   ],
   "source": [
    "#学習させるパラメータを格納\n",
    "params_to_update=[]\n",
    "#学習させるパラメータ名\n",
    "update_param_names=['classfilter.0.weight', 'classfilter.0.bias', 'classfilter.2.weight']\n",
    "\n",
    "#対象以外は購買計算をせず、変化しないようにもする\n",
    "for name,param in mymodel.named_parameters():\n",
    "    if name in update_param_names:\n",
    "        param.requires_grad = True\n",
    "        params_to_update.append(param)\n",
    "        print(\"name : \",name)\n",
    "    else:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80179db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#optimizer = optim.SGD(params_to_update, lr=0.01)\n",
    "optimizer = optim.SGD(params_to_update, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e9128b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hase\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tensor() got an unexpected keyword argument 'grad_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3569d021ac9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m                         \u001b[1;31m#print(label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0moutput_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0moutput_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                \u001b[1;31m# labels=labels.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: tensor() got an unexpected keyword argument 'grad_fn'"
     ]
    }
   ],
   "source": [
    "#エポック数\n",
    "num_epochs=20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1,num_epochs))\n",
    "    \n",
    "    for phase in ['train','valid']:\n",
    "        if phase == 'train':\n",
    "            mymodel.train()#学習モード\n",
    "        else:\n",
    "            mymodel.eval()#検証？\n",
    "    \n",
    "        #epoch全体の損失の輪と正解数\n",
    "        epoch_loss=0.0\n",
    "        epoch_corrects=0\n",
    "        \n",
    "        count=0.0\n",
    "        #print(phase)\n",
    "        for inputs, labels in dataloader_dict[phase]:\n",
    "            #入力の確認\n",
    "            #print(len(inputs),len(labels))\n",
    "            #optimizer?を初期化?する?\n",
    "            optimizer.zero_grad()\n",
    "            print(len(inputs))\n",
    "            output_models=[]\n",
    "            output_labels=[]\n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    "\n",
    "                #outputs=mymodel(torch.tensor([model(input).tolist()[0] for input in inputs]).to(device))\n",
    "               #0906 これ([0])はあかんやろってなった\n",
    "                for i, label in zip(inputs, labels):\n",
    "                    out1=model(i)\n",
    "                    output=mymodel(out1)\n",
    "                    #print(output)\n",
    "                    for h in output:\n",
    "                       # print(h.tolist())\n",
    "                        output_models.append(h.tolist())\n",
    "                        #output_models.append(h)\n",
    "                        output_labels.append(label.tolist())\n",
    "                        count+=1\n",
    "                        #print(label)\n",
    "                \n",
    "                output_models=torch.tensor(output_models, device=device, grad_fn=output.grad_fn)\n",
    "                output_labels=torch.tensor(output_labels, device=device)\n",
    "               # labels=labels.to(device)\n",
    "                #print(output_models)\n",
    "                loss=criterion(output_models, output_labels)\n",
    "                \n",
    "                #ラベルを予測\n",
    "                _,preds = torch.max(output_models,1)\n",
    "                \n",
    "                #訓練時は逆伝搬の計算\n",
    "                if phase == \"train\":\n",
    "                    #逆伝搬\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    #パラメータ更新\n",
    "                    optimizer.step()\n",
    "                \n",
    "                #イテレーション結果の計算\n",
    "                #lossの合計を更新\n",
    "                #pytorchの使用上バッチ内の平均lossが計算されているのでデータ数をかけて合計にする\n",
    "                #損失和を「全データの損失/データ数」で求めるせいらしい?\n",
    "                #print(len(inputs))\n",
    "                #epoch_loss += loss.item() * inputs.size(0)\n",
    "                epoch_loss += loss.item()*output_labels.size(0)\n",
    "                \n",
    "                #正解数の合計を更新\n",
    "                #epoch_corrects += torch.sum(preds == labels.data)\n",
    "                #print(preds.size(),count,output_labels.size(0))\n",
    "                #print()\n",
    "                epoch_corrects += torch.sum(preds == output_labels)\n",
    "        #epochのlossと正解数の表示\n",
    "        #epoch_loss=epoch_loss/len(dataloader_dict[phase])\n",
    "        #epoch_acc=epoch_corrects.double()/len(dataloader_dict[phase].dataset)\n",
    "        #print(epoch_loss, epoch_corrects.double(), count)\n",
    "        epoch_loss=epoch_loss/count\n",
    "        epoch_acc=epoch_corrects.double()/count\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m = nn.Softmax(dim=2)\n",
    "input = torch.randn(4, 4)\n",
    "output = m(input)\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0db113",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "input = torch.randn(2)\n",
    "output = m(input)\n",
    "print(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(\"C:/Users/hase/git/youtubedl/result/Speech/--aE2O5G5WE.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562ad1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b45a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f8e7787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7255,  0.1400, -0.2283,  2.8252, -2.2803],\n",
      "        [ 1.2004,  0.8045,  1.0707,  1.0409,  1.2993],\n",
      "        [ 1.4840,  0.0255,  0.0423,  0.6021,  1.4970]], requires_grad=True)\n",
      "tensor([2, 2, 1])\n",
      "tensor(2.4764, grad_fn=<NllLossBackward>)\n",
      "<NllLossBackward object at 0x000001D0BBD8A2B0>\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(input,target,output, sep='\\n')\n",
    "print(output.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92da7082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a81b581",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d4bd5a1a464f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "a.append([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ee9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459ef847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013da01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2c9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bcca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed3a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
